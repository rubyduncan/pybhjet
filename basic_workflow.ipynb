{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import sys\n",
    "import builtins\n",
    "import corner\n",
    "import astromodels\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from ultranest.integrator import read_file\n",
    "from ultranest.plot import runplot, traceplot\n",
    "\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "from emcee.autocorr import integrated_time\n",
    "\n",
    "from setup_define_scripts import (load_data_from_yaml, load_params_priors_from_yaml, \n",
    "                                  build_components_from_yaml, build_spectrum, build_model_and_data_from_yaml,\n",
    "                                  kev_plot_xylike_with_ind_model, hz_plot_xylike_data, \n",
    "                                  plot_ogip_with_model, hz_plot_model_space_sed,quick_eval,\n",
    "                                  hz_eval_and_plot_sed, add_bhjet_radiative_components_to_plot, \n",
    "                                  )\n",
    "\n",
    "\n",
    "from threeML.io.logging import silence_warnings\n",
    "silence_warnings()\n",
    "\n",
    "from threeML import *\n",
    "from threeML import (\n",
    "    SmoothlyBrokenPowerLaw,TbAbs,ZDust,\n",
    "    Constant, PointSource,Model,DataList,Log_uniform_prior,\n",
    "    Uniform_prior,Truncated_gaussian,Log_normal,\n",
    ")\n",
    "\n",
    "from threeML.utils.OGIP.response import OGIPResponse\n",
    "%matplotlib inline\n",
    "_suffix_re = re.compile(r\"_(\\d+)$\")\n",
    "\n",
    "sys.path.append(\"PyBHJet/\")\n",
    "from pybhjet_3ml import BHJetModel\n",
    "from importing_data import * #converts normal data into expected threeml units \n",
    "from unit_conversion import * #unit conversions after bhjet is run\n",
    "from bhjet_plotting import * #controlling the output \n",
    "\n",
    "def _bhjet_safe_clone_model(model_instance):\n",
    "    return model_instance\n",
    "astromodels.clone_model = _bhjet_safe_clone_model\n",
    "\n",
    "\n",
    "latex_map = {\n",
    "    \"pspec\": r\"$p$\",\n",
    "    \"z_diss\": r\"$z_{\\rm diss}$\",\n",
    "    \"z_acc\": r\"$z_{\\rm acc}$\",\n",
    "    \"jetrat\": r\"$N_j$\", \n",
    "    \"r\": r\"$r$\", \n",
    "    \"t_e\": r\"$T_e$\", \n",
    "    \"f_heat\": r\"$f_{\\rm heat}$\", \n",
    "    \"f_sc\": r\"$f_{\\rm sc}$\",\n",
    "    \"e_bmv\": r\"$A_v$\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d96335",
   "metadata": {},
   "source": [
    "##### 0. If there are issues with importing bhjet model or any of the other scripts in the PyBHJet dir, check the paths for the sys.path to make sure that they point to the main directory for pybhjet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c1fe59",
   "metadata": {},
   "source": [
    "##### Step 1: First, to load the data, this is done via a yaml file: ```model_data_load.yaml```\n",
    " \n",
    " The first section is ```data```: this will take two kinds of data: XYLike (flux) and OGIP (counts). The section names that are supplied to these two are how they will be used to be referred to/plotted later (e.g. right now they are \"flux_data_catgegory\" and \"ogip_data_category\")\n",
    "\n",
    " _________________\n",
    "\n",
    " ##### **Loading flux data**: \n",
    "1. ```kind```: always should be \"combine_dataframes\" -> this supplies the data to a function (importing_data.py) that expects that your files are (hz, mJy, mJy_err). \n",
    "    1. It also expects that your data is divided into files (can be multiple) for radio, IR, and Opt-UV, (e.g. NGC4594_radio.dat, NGC4594_IR.dat, NGC4594_UV.dat). \n",
    "    2. It will convert the data to the units that threeml expects: (diff. photon flux, keV) and return three XYLike objects that threeml expects, which are named in the code rad, ir, uv.  \n",
    "2. ```directory```: \"path/to/files\" (from where the yaml is located) \n",
    "3. ```extension```: suffix of your file type \n",
    "4. ```columns```: this can be left as is, if your data is correctly supplied as (hz, mJy, mJy_err) \n",
    "\n",
    "_________________\n",
    "\n",
    "##### **Loading OGIP data** \n",
    "1. ```kind```: will always be set to \"ogip\" \n",
    "2. ```observation```: \"path/to/files\" (from where the yaml is located)\n",
    "3. ```arf_file```:     \"path/to/files\" \n",
    "4. ```response```:     \"path/to/files\" \n",
    "5. ```background```:   \"path/to/files\" \n",
    "6. ```energy_range```: input \n",
    "7. ```rebin_on_source```: input \n",
    "\n",
    "_________________\n",
    "\n",
    "##### **Assigning Sources**: \n",
    "\n",
    "Each dataset needs to be turned into it's own \"source\" in threeml, so the next section creates a source for each one (e.g. src_radio), assigns the dataset loaded (named rad, ir, uv), and also the \"spectrum\". Can leave RA, Dec at 0,0. \n",
    "\n",
    "ra: 0.0 \\\n",
    "dec: 0.0 \\\n",
    "spectrum: radio_model \\\n",
    "datasets: [rad] \n",
    "\n",
    "\n",
    "ra: 0.0 \\\n",
    "dec: 0.0 \\\n",
    "spectrum: irvu_model \\\n",
    "datasets: [ir, uv]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf59f7f",
   "metadata": {},
   "source": [
    "##### Step 2: Model Definition, this is done via a yaml file: ```model_data_load.yaml```\n",
    "\n",
    "The second section is ```model```. This will include as few/many components as you plan to use for fitting all your data. This is where the model objects are assigned to names. \n",
    "\n",
    "In ```components```, you need to specifically use the name as provided from pybhjet/Xspec/threeml. Do not include parentheses after the name! You can then assign each model component to a \"colloquial\" name that you'll use, e.g. : \n",
    "\n",
    "jet: BHJetModel \\\n",
    "gal_ext: TbAbs \\\n",
    "intr_ext: TbAbs \\\n",
    "dust_ext: ZDust \\\n",
    "\n",
    "_________________\n",
    "\n",
    "Then, in ```spectra```, you'll decide which components you want applied to which datasets. The way that you form these model compositions will depend on the names that you gave them in ```components```. \n",
    "\n",
    "radio_model: jet \\\n",
    "iruv_model: dust_ext * jet \\\n",
    "xray_model: gal_ext * intr_ext * jet\n",
    "_________________\n",
    "\n",
    "Thirdly, in ```sed_components``` - this is repetitive from spectra, but relates to the plotting. Eventually I will make this consistent and just use the previous components: \n",
    "\n",
    "jet: jet \\\n",
    "dust_times_jet: dust_ext * jet \\\n",
    "abs_times_jet: gal_ext * intr_ext * jet\n",
    "\n",
    "_________________\n",
    "\n",
    "##### Step 3: Model Parameters, this is also done via a yaml file: ```model_data_load.yaml```\n",
    "\n",
    "Create a section under ```parameters``` for each model ```component``` that was created earlier. This is where each indiviudal parameter value will be set, fixed/free, and priors: \n",
    "\n",
    "value: 5.9 \\\n",
    "free: true \\\n",
    "bounds: [2.0, 10.0] \\\n",
    "prior: {type: uniform, min: 2.0, max: 10.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e39ae",
   "metadata": {},
   "source": [
    "##### **Actually Loading Data & Model**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c200f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yaml_path = \"ngc4594/model_data_load.yaml\"\n",
    "data_yaml_path = 'ngc4594/model_data_load.yaml'\n",
    "\n",
    "model_obj, data_obj, model_components, data_dict, sources, sed_comp = build_model_and_data_from_yaml(data_yaml_path, model_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07275fb4",
   "metadata": {},
   "source": [
    "This is a shortcut way to see the parameters for each of your components that you assign: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87806bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet = model_components[\"jet\"]\n",
    "gal_ext = model_components[\"gal_ext\"]\n",
    "dust_ext = model_components[\"dust_ext\"]\n",
    "intr_ext = model_components[\"intr_ext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet.free_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f318f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = hz_plot_model_space_sed(data_dict, model_components, sed_comp)\n",
    "add_bhjet_radiative_components_to_plot(model_components, ax) \n",
    "\n",
    "plt.ylim(1e-17, 1e-10)\n",
    "plt.xlim(1e8, 1e20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ef506",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ogip_with_model(data_dict['ogip_data_category'], model_obj = model_obj, model_labels=['Chandra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, stat_total, per_stats = hz_eval_and_plot_sed(model_obj,data_dict,model_components,sed_comp)\n",
    "plt.ylim(1e-17, 1e-10)\n",
    "plt.xlim(1e8, 1e20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febaccce",
   "metadata": {},
   "source": [
    "#### Testing MCMC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhjet_ba = BayesianAnalysis(model_obj, data_obj)\n",
    "bhjet_ba.set_sampler(\"emcee\")\n",
    "\n",
    "n_dim = len(model_obj.free_parameters)\n",
    "n_walkers = 3 * n_dim   \n",
    "# n_threads = min(8, n_walkers) \n",
    "\n",
    "burn_in = 5                                  \n",
    "n_samples = 10      \n",
    "\n",
    "bhjet_ba.sampler.setup(\n",
    "    n_walkers=n_walkers,\n",
    "    share_spectrum = True,\n",
    "    n_burn_in=burn_in,\n",
    "    n_iterations=n_samples,\n",
    "    # n_threads=n_threads,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# bhjet_ba.sample()\n",
    "# res_emcee_bpl = ba.results\n",
    "# res_emcee_bpl.write_to(\"test2.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02f08e",
   "metadata": {},
   "source": [
    "Testing Nested Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultranest.stepsampler\n",
    "\n",
    "ba = BayesianAnalysis(model_obj, data_obj)\n",
    "ba.set_sampler(\"ultranest\")\n",
    "\n",
    "#slice sampler in ultranest \n",
    "n_steps = 2 * len(model_obj.free_parameters)\n",
    "ba.sampler.setup(stepsampler = ultranest.stepsampler.SliceSampler(nsteps=n_steps, generate_direction=ultranest.stepsampler.generate_mixture_random_direction))\n",
    "\n",
    "#ba.sample()\n",
    "# res_emcee_bpl = ba.results\n",
    "# res_emcee_bpl.write_to(\"test2.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb23266",
   "metadata": {},
   "source": [
    "Output Stuff: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba400f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strip_threeml_index_from_tail(full_name: str) -> str:\n",
    "    '''annoying workaround for the numbers that threeml adds '''\n",
    "    parts = full_name.split(\".\")\n",
    "    parts[-1] = _suffix_re.sub(\"\", parts[-1], count=1)\n",
    "    return \".\".join(parts)\n",
    "\n",
    "def reduce_to_tail_key(full_name: str) -> str:\n",
    "    \"\"\"\n",
    "    turn full 3ml parameter name to a key for plotting (assigned to latex names)\n",
    "    src_xray.spectrum.main.composite.jetrat_1 -> jetrat\n",
    "    \"\"\"\n",
    "    stripped = _strip_threeml_index_from_tail(full_name)\n",
    "    return stripped.split(\".\")[-1]\n",
    "\n",
    "def set_model_un_output(model_obj, post_path, value_col: str = \"median\"):\n",
    "    \n",
    "    free_params = model_obj.free_parameters  # OrderedDict of all the param names \n",
    "\n",
    "    base_to_full = {}\n",
    "    for full_name in free_params.keys():\n",
    "        base = _strip_threeml_index_from_tail(full_name)\n",
    "        if base not in base_to_full:\n",
    "            base_to_full[base] = full_name\n",
    "\n",
    "    # assign values\n",
    "    for name, val in zip(summary_eq[\"name\"].values, summary_eq[value_col].values):\n",
    "        base = _strip_threeml_index_from_tail(name)\n",
    "        full = base_to_full.get(base)\n",
    "        if full is None:\n",
    "            continue\n",
    "        \n",
    "        free_params[full].value = float(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_chains_eq_post(path, summary=False): \n",
    "\n",
    "    '''returns a numpy array with each row corresponding to a step, with samples for each parameter at that step, \n",
    "    columns corresponding to each parameter \n",
    "    '''\n",
    "    \n",
    "    chains_path = Path(path + \"chains\")\n",
    "    eq_wpost_path = chains_path / \"chains/equal_weighted_post.txt\" \n",
    "    equ_post_df = pd.read_csv(eq_wpost_path,sep='\\s+',comment=\"#\")\n",
    "    equ_post_df.columns = [reduce_to_tail_key(c) for c in equ_post_df.columns]\n",
    "    labels = [latex_map.get(c, c) for c in equ_post_df.columns]\n",
    "\n",
    "    if summary == True: \n",
    "        ndim = len(model_obj.free_parameters)  \n",
    "        sequence, final = read_file(chains_path, x_dim=ndim)\n",
    "\n",
    "        summary_eq = pd.DataFrame(\n",
    "        {\n",
    "            \"name\": equ_post_df.columns,\n",
    "            \"min\": equ_post_df.min(axis=0).values,\n",
    "            \"max\": equ_post_df.max(axis=0).values,\n",
    "            \"mean\": equ_post_df.mean(axis=0).values,\n",
    "            \"median\": equ_post_df.median(axis=0).values,\n",
    "            \"std\": equ_post_df.std(axis=0).values,\n",
    "        }\n",
    "        )\n",
    "        return summary_eq, sequence, chains_path\n",
    "    \n",
    "    else: \n",
    "        samples = equ_post_df.to_numpy(dtype=float)\n",
    "        return samples, labels, chains_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_eq, sequence, chains_path = return_chains_eq_post(path, summary=True)\n",
    "set_model_un_output(model_obj, summary_eq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "threeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
